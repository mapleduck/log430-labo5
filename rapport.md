# LOG430 - Rapport du laboratoire 02
Ã‰TS - LOG430 - Architecture logicielle - Hiver 2026 - Groupe 1

Ã‰tudiant: Yanni Haddar
Nom github: mapleduck
repo github: https://github.com/mapleduck/log430-labo5 et https://github.com/mapleduck/log430-labo5-payment

## Questions

> ğŸ’¡ Question 1 : Quelle rÃ©ponse obtenons-nous Ã  la requÃªte Ã  POST /payments ? Illustrez votre rÃ©ponse avec des captures d'Ã©cran/du terminal.

Le body de la requÃªte spÃ©cifie manuellement l'existence d'un order, et nous devrions donc recevoir un id de paiement pour pouvoir le process:
```
{
    "user_id": 1,
    "order_id": 1,
    "total_amount": 99.53
}
```
Nous recevont tout simplement un ID de payment. Ce test a Ã©tÃ© fait aprÃ¨s 4 tentatives de payment process (j'ai pris trop d'avance par rapport Ã  l'activitÃ©), il s'agit simplement de l'incrÃ©mentation normale:
<div style="text-align: center;">
  <img src="./docs/img/Q1.png" style="width: 75%; padding: 15px;">
</div>

> ğŸ’¡ Question 2 : Quel type d'information envoyons-nous dans la requÃªte Ã  POST payments/process/:id ? Est-ce que ce serait le mÃªme format si on communiquait avec un service SOA, par exemple ? Illustrez votre rÃ©ponse avec des exemples et captures d'Ã©cran/terminal.

Nous envoyons en JSON des informations de paiement d'une carte de crÃ©dit:
<div style="text-align: center;">
  <img src="./docs/img/Q2_3.png" style="width: 75%; padding: 15px;">
</div>

En SOA, ces informations seraient dans un format plus strict, en XML, avec des Enveloppes SOAP et un format tr's spÃ©cifique (il faut respecter un fichier WSDL).

> ğŸ’¡ Question 3 : Quel rÃ©sultat obtenons-nous de la requÃªte Ã  POST payments/process/:id?

On peut voir dans l'image ci-haut que l'API rÃ©ponds avec l'order ID, le payment ID, et la confirmation que l'order a Ã©tÃ© marquÃ© comme payÃ© (is_paid = true).

> ğŸ’¡ Question 4 : Quelle mÃ©thode avez-vous dÃ» modifier dans log430-labo05-payment et qu'avez-vous modifiÃ©e ? Justifiez avec un extrait de code.

La mÃ©thode `update_order` dans `payment_controller.py` est celle qui a dÃ» Ãªtre modifiÃ©e (l'implÃ©mentation de la mÃ©thode devait Ãªtre faite). En gros, la mÃ©thode fait un call Ã  l'API pour mettre Ã  jour la commande et le fait qu'elle a Ã©tÃ© payÃ©e. Il a aussi fallu adapter le call de update_order plus haut dans le fichier:
<div style="text-align: center;">
  <img src="./docs/img/Q4.png" style="width: 75%; padding: 15px;">
</div>

> ğŸ’¡ Question 5 : Ã€ partir de combien de requÃªtes par minute observez-vous les erreurs 503 ? Justifiez avec des captures d'Ã©cran de Locust.

Ã€ partir de 6 requÃªtes par seconde.
<div style="text-align: center;">
  <img src="./docs/img/Q5.png" style="width: 75%; padding: 15px;">
</div>

> ğŸ’¡ Question 6 : Que se passe-t-il dans le navigateur quand vous faites une requÃªte avec un dÃ©lai supÃ©rieur au timeout configurÃ© (5 secondes) ? Quelle est l'importance du timeout dans une architecture de microservices ? Justifiez votre rÃ©ponse avec des exemples pratiques.

Voici la requÃªte de secondes, elle fonctionne comme prÃ©vu et renvoie ceci aprÃ¨s 2 secondes:
<div style="text-align: center;">
  <img src="./docs/img/Q6_1.png" style="width: 75%; padding: 15px;">
</div>

La requÃªte de 10 secondes n'a jamais complÃ©tÃ©e. Le navigateur indique une erreur 500 aprÃ¨s 5 secondes exactement.
<div style="text-align: center;">
  <img src="./docs/img/Q6_2.png" style="width: 75%; padding: 15px;">
</div>

Le timeout agit comme une protection qui empÃªche un service lent de causer un effet snowball, ou le service monopolise les ressources, causant d'autres services de aussi ralentir. En forcant un Ã©chec rapide, on protÃ¨ge la stabilitÃ© et la disponibilitÃ© de tout le systÃ¨me et on Ã©vite que la panne se propage. Ceci est d'une grande importance dans l'architecture microservice.

## Test de charge (activitÃ© 7)
Les tests de charge ont Ã©tÃ© effectuÃ©s sur 120s avec 150 users peak et un spawn rate de 2 users par seconde. Les tests ont Ã©tÃ© effectuÃ©s sur ma machine dÃ» Ã  un problÃ¨me de connexion au rÃ©seau de l'Ã©cole, que je rÃ¨glerai d'ici le prochain labo.

### Tentative #1 avec les paramÃ¨tres par dÃ©faut, en faisant un POST sur les orders (voir locustfile ligne 37).
TrÃ¨s rapidement, un taux Ã©norme d'erreur (>90%) a Ã©tÃ© atteint, quasiment que des erreurs 503. En regardant la console docker de KrakenD, le problÃ¨me est Ã©vident:
```
[GIN] 2026/02/26 - 19:01:53 | 503 |      20.707Âµs |      172.21.0.5 | POST     "/store-manager-api/orders"
Error #01: rate limit exceded
[GIN] 2026/02/26 - 19:01:54 | 503 |      18.792Âµs |      172.21.0.5 | POST     "/store-manager-api/orders"
Error #01: rate limit exceded
```
KrakenD avait un taux maximal de 200 requÃªtes par minutes, ce que notre test de charge oblitÃ©rait. J'ai donc modifiÃ© le taux maximal Ã  une valeur plus libÃ©rale de 2000 par minute:
```
"max_rate": 2000,
```
De plus, les timeouts ont Ã©tÃ© mis Ã  15 secondes. Comme ca, on s'assure que le test de charge s'applique sur les failure points du backend et non simplement la config KrakenD.

### Tentative #2 avec les nouveaux paramÃ¨tres KrakenD
RÃ©sultat: Taux d'erreur trÃ¨s stable de 50% pendant les premiÃ¨res 60 secondes, montant jusqu'Ã  77% vers la toute fin.

<div style="text-align: center;">
  <img src="./docs/img/1.png" style="width: 75%; padding: 15px;">
</div>

En regardant les taux d'erreurs, on voit que encore qu'une partie non nÃ©gligeable (25%) des ereurs sont dÃ»es au rate limiter (503):

<div style="text-align: center;">
  <img src="./docs/img/2.png" style="width: 75%; padding: 15px;">
</div>

C'est lÃ  que j'ai eu une rÃ©alisation. Lors du labo 2, il y avait dans le locustfile deux tests de GET et un test de POST, tous avec un weight de 1. Cela signifiait que pour chaque requÃªte POST, il y avait en moyenne deux requÃªtes GET.

Or, mon locustfile actuel ne contient qu'une seule task, un POST. Cela veut dire que chacune des transactions effectuÃ©es par Locust est un POST. Les POST sont significativement plus lourd Ã  handle, et cela explique le taux d'Ã©chec catastrophique comparÃ© au labo 4, et le fait qu'il reste encore des rate limit errors.

Pour reproduire des conditions similaires au labo 4, j'ai donc rajoutÃ© un GET sur un order random entre 1 et 100 (pas le meilleur design, mais ca fera l'affaire, l'existence des orders 1 Ã  100 est guarantie dans mon cas), et j'ai donnÃ© Ã  ce test un weight de 2, pour qu'il soit appelÃ© deux fois plus souvent en moyenne que le POST.

### Tentative #3 avec le nouveau GET
RÃ©sultat: Le taux d'Ã©chec est descendu de facon significative, Ã©tant Ã  14-19% pour les requÃªtes overall et 40% pour les POST uniquement, ce qui ressemble beaucoup plus Ã  mon labo 4:

<div style="text-align: center;">
  <img src="./docs/img/3.png" style="width: 75%; padding: 15px;">
</div>

Les erreurs 503 sont entiÃ¨rements parties:

<div style="text-align: center;">
  <img src="./docs/img/4.png" style="width: 75%; padding: 15px;">
</div>

Le haut taux d'erreurs sur les POST reste un problÃ¨me, mais cela est une consÃ©quence de rouler tout les services en plus du service de test sur la mÃªme machine. Des rÃ©sultats plus positifs devraient avoir lieu lorsque la charg est balancÃ©e comme il faut.