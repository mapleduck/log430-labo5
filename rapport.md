# LOG430 - Rapport du laboratoire 02
√âTS - LOG430 - Architecture logicielle - Hiver 2026 - Groupe 1

√âtudiant: Yanni Haddar
Nom github: mapleduck
repo github: https://github.com/mapleduck/log430-labo5 et https://github.com/mapleduck/log430-labo5-payment

## Questions

> üí° Question 1 : Quelle r√©ponse obtenons-nous √† la requ√™te √† POST /payments ? Illustrez votre r√©ponse avec des captures d'√©cran/du terminal.

Le body de la requ√™te sp√©cifie manuellement l'existence d'un order, et nous devrions donc recevoir un id de paiement pour pouvoir le process:
```
{
    "user_id": 1,
    "order_id": 1,
    "total_amount": 99.53
}
```
Nous recevont tout simplement un ID de payment. Ce test a √©t√© fait apr√®s 4 tentatives de payment process (j'ai pris trop d'avance par rapport √† l'activit√©), il s'agit simplement de l'incr√©mentation normale.

<p align="center">
  <img src="./docs/img/Q1.png" width="75%">
</p>

> üí° Question 2 : Quel type d'information envoyons-nous dans la requ√™te √† POST payments/process/:id ? Est-ce que ce serait le m√™me format si on communiquait avec un service SOA, par exemple ? Illustrez votre r√©ponse avec des exemples et captures d'√©cran/terminal.

Nous envoyons des informations de paiement d'une carte de cr√©dit.
![5](./docs/img/Q2_3.png)
En SOA, ces informations 


## Test de charge (activit√© 7)
Les tests de charge ont √©t√© effectu√©s sur 120s avec 150 users peak et un spawn rate de 2 users par seconde. Les tests ont √©t√© effectu√©s sur ma machine d√ª √† un probl√®me de connexion au r√©seau de l'√©cole, que je r√®glerai d'ici le prochain labo.

### Tentative #1 avec les param√®tres par d√©faut, en faisant un POST sur les orders (voir locustfile ligne 37).
Tr√®s rapidement, un taux √©norme d'erreur (>90%) a √©t√© atteint, quasiment que des erreurs 503. En regardant la console docker de KrakenD, le probl√®me est √©vident:
```
[GIN] 2026/02/26 - 19:01:53 | 503 |      20.707¬µs |      172.21.0.5 | POST     "/store-manager-api/orders"
Error #01: rate limit exceded
[GIN] 2026/02/26 - 19:01:54 | 503 |      18.792¬µs |      172.21.0.5 | POST     "/store-manager-api/orders"
Error #01: rate limit exceded
```
KrakenD avait un taux maximal de 200 requ√™tes par minutes, ce que notre test de charge oblit√©rait. J'ai donc modifi√© le taux maximal √† une valeur plus lib√©rale de 2000 par minute:
```
"max_rate": 2000,
```
De plus, les timeouts ont √©t√© mis √† 15 secondes. Comme ca, on s'assure que le test de charge s'applique sur les failure points du backend et non simplement la config KrakenD.

### Tentative #2 avec les nouveaux param√®tres KrakenD
R√©sultat: Taux d'erreur tr√®s stable de 50% pendant les premi√®res 60 secondes, montant jusqu'√† 77% vers la toute fin.
![1](./docs/img/1.png)

En regardant les taux d'erreurs, on voit que encore qu'une partie non n√©gligeable (25%) des ereurs sont d√ªes au rate limiter (503):
![2](./docs/img/2.png)

C'est l√† que j'ai eu une r√©alisation. Lors du labo 2, il y avait dans le locustfile deux tests de GET et un test de POST, tous avec un weight de 1. Cela signifiait que pour chaque requ√™te POST, il y avait en moyenne deux requ√™tes GET.

Or, mon locustfile actuel ne contient qu'un seul poste. Cela veut dire que chacune des transactions effectu√©es par Locust sont des POST. Les POST sont significativement plus lourd √† handle, et cela explique le taux d'√©chec catastrophique compar√© au labo 4, et le fait qu'il reste encore des rate limit errors.

Pour reproduire des conditions similaires au labo 4, j'ai donc rajout√© un GET sur un order random entre 1 et 100 (pas le meilleur design, mais ca fera l'affaire, l'existence des orders 1 √† 100 est guarantie dans mon cas), et j'ai donn√© √† ce test un weight de 2, pour qu'il soit appel√© deux fois plus souvent en moyenne que le POST.

### Tentative #3 avec le nouveau GET
R√©sultat: Le taux d'√©chec est descendu de facon significative, √©tant √† 14-19% pour les requ√™tes overall et 40% pour les POST uniquement, ce qui ressemble beaucoup plus √† mon labo 4:
![3](./docs/img/3.png)

Les erreurs 503 sont enti√®rements parties:
![4](./docs/img/4.png)

Le haut taux d'erreurs sur les POST reste un probl√®me, mais cela est une cons√©quence de rouler tout les services en plus du service de test sur la m√™me machine. Des r√©sultats plus positifs devraient avoir lieu lorsque la charg est balanc√©e comme il faut.