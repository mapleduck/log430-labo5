# Tutoriel de dÃ©ploiement avec k3s
<img src="https://upload.wikimedia.org/wikipedia/commons/2/2a/Ets_quebec_logo.png" width="250">    
Ã‰TS - LOG430 - Architecture logicielle - ChargÃ© de laboratoire : Gabriel C. Ullmann, Hiver 2026.

---

Dans ce tutoriel, vous allez utiliser [k3s](https://k3s.io/), une version simplifiÃ©e de [Kubernetes](https://github.com/kubernetes/kubernetes) (k8s), pour crÃ©er une grappe avec 2 serveurs et dÃ©ployer l'application de votre environnement de dÃ©veloppement Ã  votre environnement de production de maniÃ¨re semi-automatique, en pouvant rÃ©pliquer votre application et ajouter plusieurs nÅ“uds Ã  la grappe de maniÃ¨re simple.

## ğŸ¯ Objectifs d'apprentissage
- Apprendre Ã  utiliser [k3s](https://k3s.io/), une version simplifiÃ©e de Kubernetes
- Apprendre Ã  utiliser [Docker Hub](https://hub.docker.com/r/nkinesis/store-manager) pour hÃ©berger vos images Docker
- Se familiariser avec la terminologie des grappes de serveurs (master, worker, node, pod, service)
- Comprendre les avantages d'utiliser un orchestrateur de conteneurs par rapport Ã  simplement utiliser les conteneurs Docker

## ğŸ’» Exigences du projet
Vous aurez besoin de :
- ğŸ  Votre ordinateur (votre environnement de dÃ©veloppement, le nÅ“ud **worker**) contenant le code de ce dÃ©pÃ´t avec des implÃ©mentations recommendÃ©s dans le README
- â˜ï¸ 1 VM distante avec IP fixe (votre environnement de production, le nÅ“ud **master**)
- Un compte Docker (vous pouvez en crÃ©er un gratuitement sur le site web)

Pour faciliter la comprÃ©hension des instructions, votre environnement de dÃ©veloppement sera symbolisÃ© par un emoji maison ğŸ  et votre VM ou serveur distant sera symbolisÃ©e par un emoji nuage â˜ï¸.

## â“ Questions frÃ©quentes

### Pourquoi ne pas configurer plutÃ´t le nÅ“ud master dans mon environnement de dÃ©veloppement? 
Pour simplifier la configuration rÃ©seau, il est prÃ©fÃ©rable que le nÅ“ud master ait une IP fixe. Les workers peuvent avoir n'importe quelle adresse IP, et elle peut changer Ã  n'importe quel moment sans impact sur notre configuration, car chaque fois que l'IP change, le worker se reconnecte au master. 

### J'ai vu d'autres tutoriels de Kubernetes et c'est diffÃ©rent. Quelle est la bonne maniÃ¨re de le faire ?
Il existe plusieurs faÃ§ons diffÃ©rentes d'installer Kubernetes, et cela variera en fonction de votre configuration rÃ©seau, du nombre de serveurs dans la grappe, de la technologie de conteneurs utilisÃ©e, etc. Ici, nous avons choisi `k3s` parce que c'est une solution simple et rapide pour crÃ©er une petite grappe de serveurs qui sert des applications conteneurisÃ©es avec Docker (comme Store Manager, par exemple).

### Pourquoi mon nÅ“ud k3s ne dÃ©marre-t-il pas ?
Veuillez suivre attentivement les instructions et vÃ©rifier si votre serveur dispose de ressources de calcul suffisantes (RAM, CPU et stockage). 2 Go de RAM devraient suffire pour ce tutoriel. Si nÃ©cessaire, arrÃªtez ou supprimez les autres conteneurs prÃ©sents sur votre serveur afin d'Ã©conomiser des ressources.

## âš™ï¸ Setup

### 1. Configurez le nÅ“ud master â˜ï¸

Installez `k3s` :
```bash
curl -sfL https://get.k3s.io | sh -
```

VÃ©rifiez que le nÅ“ud est prÃªt :
```bash
kubectl get nodes
```

Voici le rÃ©sultat attendu :
```bash
NAME              STATUS   ROLES           
log430-votre-vm   Ready    control-plane  
```

Affichez le jeton pour connecter des nÅ“uds supplÃ©mentaires et copiez-le :
```bash
cat /var/lib/rancher/k3s/server/node-token
```

Affichez le fichier de configuration et copiez-le :
```bash
cat /etc/rancher/k3s/k3s.yaml
```

### 2. Configurez l'accÃ¨s depuis votre machine de dÃ©veloppement ğŸ 

Indiquez la bonne adresse IP de votre VM (`<ip-vm>`) et le jeton (`<token>`) :
```bash
curl -sfL https://get.k3s.io | K3S_URL=https://<ip-vm>:6443 K3S_TOKEN=<token> sh -
```

> ğŸ“ **NOTE** : Si votre machine de dÃ©veloppement utilise une architecture ARM (Apple Silicon), vous devez d'abord installer `k3d` (`brew install k3d`). Au lieu d'installer `k3s` directement dans le systÃ¨me d'exploitation, cela exÃ©cutera `k3s` dans un conteneur Docker qui crÃ©e une couche de compatibilitÃ© entre l'image `k3d` amd64 et votre systÃ¨me arm64.

Sur votre machine de dÃ©veloppement, crÃ©ez le fichier `kubeconfig`. Dans ce fichier, collez le contenu copiÃ© depuis le fichier `k3s.yaml` pendant l'Ã©tape prÃ©cÃ©dante :
```bash
mkdir -p ~/.kube
nano ~/.kube/config
```

Dans le fichier, remplacez `<remote-server-ip>` par l'IP fixe de la VM :
```yaml
server: https://<remote-server-ip>:6443
```

VÃ©rifiez la connexion :
```bash
kubectl get nodes
```

Si tout est bien configurÃ©, vous devriez voir le nÅ“ud master dans la liste de nÅ“uds.

### 3. Publiez votre image sur Docker Hub ğŸ 

Docker Hub offre un nombre illimitÃ© de dÃ©pÃ´ts publics, ou jusqu'Ã  1 dÃ©pÃ´t privÃ© gratuit. Ici, nous vous recommandons d'utiliser un dÃ©pÃ´t public. Ouvrez une nouvelle fenÃªtre de terminal dans le rÃ©pertoire du projet `log430-labo5`, exÃ©cutez `docker login` et suivez les instructions pour vous authentifier dans votre navigateur.

```bash
docker login
```

Ensuite, utilisez votre nom d'utilisateur pour crÃ©er et tÃ©lÃ©verser une nouvelle image. Remplacez `<nom-app>` par `store-manager`.
```bash
docker build -t <nom-utilisateur>/<nom-app>:latest .
docker push <nom-utilisateur>/<nom-app>:latest
```

> ğŸ“ **NOTE** : Si votre machine de dÃ©veloppement utilise une architecture ARM (Apple Silicon), vous devez construire une image multi-plateforme pour qu'elle fonctionne sur une VM ou un serveur AMD64 :
```bash
docker buildx create --use
docker buildx build --platform linux/amd64,linux/arm64 -t <votre-utilisateur>/<nom-app>:latest --push .
```

Remplacez le nom de l'image dans le manifeste Kubernetes de ce dÃ©pÃ´t (`k8s-manifests.yml`) par le vÃ´tre. Si vous le souhaitez, vous pouvez conserver l'image par dÃ©faut (`nkinesis/store-manager:latest`), mais vous ne pourrez pas modifier le code de l'image puisqu'elle n'est pas dans votre compte.

### 4. CrÃ©ez les ConfigMaps ğŸ 

Les fichiers de configuration (KrakenD, base de donnÃ©es) doivent Ãªtre chargÃ©s en tant que ConfigMaps avant de dÃ©ployer :

```bash
kubectl create configmap krakend-config --from-file=krakend.json=./config/krakend.json
kubectl create configmap db-init --from-file=./db-init/
```

DÃ©ployez !

```bash
kubectl apply -f k8s-manifests.yml
```

### 5. VÃ©rifiez le dÃ©ploiement dans la VM â˜ï¸


Surveillez le dÃ©marrage des pods :
```bash
kubectl get pods -w
```

Voici le rÃ©sultat attendu :
```bash
NAME                             READY   STATUS    RESTARTS      
api-gateway-786b9dffdb-hkx2t     1/1     Running   1 (1m ago)    
mysql-5647796678-4cnws           1/1     Running   1 (1m ago)    
redis-67555ffc9b-xgtxb           1/1     Running   1 (1m ago)   
store-manager-7f675d8f65-xjc2v   1/1     Running   1 (1m ago) 
```

> ğŸ“ **NOTE** : Un **pod** consiste en un ou plusieurs conteneurs qui ont la garantie d'Ãªtre co-localisÃ©s sur une mÃªme machine et peuvent en partager les ressources de calcul.

Affichez les services et leurs ports :
```bash
kubectl get services
```

Voici le rÃ©sultat attendu :
```bash
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          
api-gateway     NodePort    10.43.5.109     <none>        8080:31628/TCP   
kubernetes      ClusterIP   10.43.0.1       <none>        443/TCP          
mysql           ClusterIP   10.43.198.200   <none>        3306/TCP         
redis           ClusterIP   10.43.61.252    <none>        6379/TCP         
store-manager   NodePort    10.43.35.136    <none>        5000:32080/TCP   
```

Les services de type `NodePort` sont accessibles depuis l'extÃ©rieur via `http://<remote-server-ip>:<port>`. Par exemple, pour se connecter Ã  Store Manager directement, utilisez Postman pour envoyer une requÃªte Ã  `http://<remote-server-ip>:32080`. Le port `32080` est sÃ©lectionnÃ© de maniÃ¨re alÃ©atoire par k3s.


> âš ï¸ **ATTENTION** : N'utilisez jamais les IP dans la colonne `CLUSTER-IP`. Ce sont les IP internes des conteneurs. Pour la communication externe, utilisez l'IP que vous avez dÃ©finie pour votre VM.

> ğŸ“ **NOTE** : Dans ce tutoriel, les services `store-manager` et `api-gateway` ont des ports ouverts vers l'extÃ©rieur pour faciliter le dÃ©bogage et l'expÃ©rimentation. Dans un environnement de production, normalement seule l'API Gateway serait ouverte vers l'extÃ©rieur.

### 6. Mettez Ã  jour l'application ğŸ 

Ã€ chaque fois que vous modifiez le code et souhaitez redÃ©ployer, reconstruisez et poussez l'image vers Docker Hub, puis redÃ©marrez le dÃ©ploiement :

```bash
docker build -t <nom-utilisateur>/<nom-app>:latest .
docker push <nom-utilisateur>/<nom-app>:latest
kubectl rollout restart deployment store-manager
```

### 7. Ajoutez un nouveau nÅ“ud k3s (optionnel)
Pour ajouter d'autres nÅ“uds Ã  la grappe (ex. une autre VM), rÃ©pÃ©tez l'Ã©tape 2.

### 8. Changez le nombre de rÃ©pliques de l'application Store Manager (optionnel)
Modifiez l'attribut `replicas` dans `k8s-manifests.yml`. Ici, nous utilisons la valeur par dÃ©faut `replicas: 1`. Alternativement :

```bash
kubectl scale deployment store-manager --replicas=3
```

La facilitÃ© d'ajout de nouveaux nÅ“uds et de nouvelles rÃ©pliques est l'un des principaux avantages de l'utilisation de k3s ou k8s. [Docker Swarm](https://docs.docker.com/engine/swarm/) offre des fonctionnalitÃ©s similaires.
