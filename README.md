# Labo 05 ‚Äì Microservices, SOA, SBA, API Gateway, Rate Limit & Timeout

<img src="https://upload.wikimedia.org/wikipedia/commons/2/2a/Ets_quebec_logo.png" width="250">    
√âTS - LOG430 - Architecture logicielle - Charg√© de laboratoire: Gabriel C. Ullmann.

## üéØ Objectifs d'apprentissage
- Apprendre √† communiquer avec un microservice d√©j√† existant
- Apprendre √† configurer et utiliser KrakenD, un API Gateway
- D√©couvrir les configurations de `timeout` (limitation du temps de r√©ponse) et `rate limiting` (limitation du nombre de requ√™tes) dans KrakenD

## ‚öôÔ∏è Setup

Dans ce labo, nous allons ajouter des fonctionnalit√©s de paiement √† notre application Store Manager. Ainsi comme nous avons les r√©pertoires `orders` et `stocks` dans notre projet, nous pourrions simplement ajouter un r√©pertoire `payments` et commencer √† √©crire nos fonctionnalit√©s de paiement. Cependant, il vaut mieux d√©velopper une application compl√®tement isol√©e dans un d√©p√¥t s√©par√© - un microservice - pour les paiements au lieu de l'ajouter au Store Manager. √áa nous donne plus de flexibilit√© de d√©ploiement et d'√©volution. Pour en savoir plus, veuillez lire la documentation architecturale dans le r√©pertoire `/docs/arc42/architecture.pdf`.

> ‚ö†Ô∏è ATTENTION : Pendant ce laboratoire, nous allons travailler avec ce d√©p√¥t (`log430-labo5`), ainsi qu'avec un **deuxi√®me d√©p√¥t**, [log430-labo5-paiement](https://github.com/guteacher/log430-labo5-payment). Veuillez lire le document `/docs/adr/adr001.md` dans `log430-labo5-paiement` pour comprendre notre choix de cr√©er un microservice s√©par√© pour les fonctionnalit√©s de paiement.

### 1. Clonez les d√©p√¥ts
Cr√©ez vos propres d√©p√¥ts √† partir des d√©p√¥ts gabarits (templates). Vous pouvez modifier la visibilit√© pour les rendre priv√©s si vous voulez.
```bash
git clone https://github.com/[votrenom]/log430-labo5
git clone https://github.com/[votrenom]/log430-labo5-payment
cd log430-labo5
```
Ensuite, clonez votre d√©p√¥t sur votre ordinateur et sur votre serveur de d√©ploiement (ex. VM). Veillez √† ne pas cloner le d√©p√¥t d'origine.

Ensuite, veuillez faire les √©tapes de setup suivantes pour les **deux d√©p√¥ts**.

### 2. Cr√©ez un fichier .env
Cr√©ez un fichier `.env` bas√© sur `.env.example`. Dans le fichier `.env`, utilisez les m√™mes identifiants que ceux mentionn√©s dans `docker-compose.yml`. Veuillez suivre la m√™me approche que pour les derniers laboratoires.

### 3. Cr√©ez un r√©seau Docker
Ex√©cutez dans votre terminal :
```bash
docker network create labo05-network
```

### 4. Pr√©parez l'environnement de d√©veloppement
Suivez les m√™mes √©tapes que pour les derniers laboratoires.
```bash
docker compose build
docker compose up -d
```

### 5. Pr√©parez l'environnement de d√©ploiement et le pipeline CI/CD
Utilisez les m√™mes approches qui ont √©t√© abord√©es lors des derniers laboratoires.

## üß™ Activit√©s pratiques

### 1. Int√©gration du service de paiement
Dans `orders/commands/write_order.py`, la fonction `add_order` effectue la cr√©ation des nouvelles commandes. Dans cette version de l'application, elle va √©galement accomplir une √©tape suppl√©mentaire : demander √† un service de paiement la cr√©ation d'une transaction de paiement, que nous garderons sous forme de lien avec la commande pour que, plus tard, on puisse payer pour la commande.

**Votre t√¢che :** dans `orders/commands/write_order.py`, compl√©tez l'impl√©mentation de la fonction `request_payment_link` pour faire un appel POST √† l'endpoint `/payments` dans le service de paiement et obtenir le `payment_id`.

```python
  response_from_payment_service = requests.post('url-to-api-gateway',
      json=payment_transaction,
      headers={'Content-Type': 'application/json'}
  )
```

> ‚ö†Ô∏è ATTENTION : Pour conna√Ætre l'URL du service de paiement, veuillez regarder dans `config/krakend.json`. Nous n'allons pas appeler le service directement, nous appellerons KrakenD et il s'occupera d'acheminer notre requ√™te vers le bon chemin. M√™me si les endpoints du service de paiement ou les hostnames changent, si nous maintenons KrakenD √† jour, aucune modification n'est n√©cessaire dans l'application Store Manager.

> üí° **Question 1** : Quelle r√©ponse obtenons-nous √† la requ√™te √† `POST /payments` ? Illustrez votre r√©ponse avec des captures d'√©cran/du terminal.

### 2. Utilisez le lien de paiement
- Dans votre Postman, importez la collection Postman qui est dans `docs/collections` √† `log430-labo5`
- Ensuite, importez aussi la collection sur `docs/collections` √† `log430-labo5-payment`

#### Dans `log430-labo5`
- Cr√©ez une commande avec `POST /orders`. Vous obtiendrez un `order_id`.
- Cherchez la commande avec `GET /order/:id`. Vous obtiendrez un `payment_id`.

#### Dans `log430-labo5-payment`
- Faites une requ√™te √† `POST payments/process/:id` en utilisant le `payment_id` obtenu. Regardez l'onglet "Body" pour voir ce qu'on est en train d'envoyer dans la requ√™te.
- Faites une requ√™te √† `GET payments/:id` en utilisant le `payment_id` obtenu. Observez le r√©sultat pour savoir si le paiement a √©t√© r√©alis√© correctement.

> üí° **Question 2** : Quel type d'information envoyons-nous dans la requ√™te √† `POST payments/process/:id` ? Est-ce que ce serait le m√™me format si on communiquait avec un service SOA, par exemple ? Illustrez votre r√©ponse avec des exemples et captures d'√©cran/terminal.

> üí° **Question 3** : Quel r√©sultat obtenons-nous de la requ√™te √† `POST payments/process/:id`?

### 3. Ajoutez un nouveau endpoint √† KrakenD
Ajoutez l'endpoint de cr√©ation de commandes √† `config/krakend.json`. Nous l'utiliserons lors des prochaines activit√©s. Ce code ajoute une [limitation du nombre de requ√™tes](https://www.krakend.io/docs/endpoints/rate-limit/) √† nos endpoints (par minute, par client).
```json
  {
      "endpoint": "/store-manager-api/orders",
      "method": "POST",
      "backend": [
        {
          "url_pattern": "/orders",
          "host": ["http://store_manager:5000"],
        }
      ],
      "extra_config": {
        "qos/ratelimit/router": {
          "max_rate": 200,
          "every": "1m",
        }
      }
  },
  {
    "endpoint": "/store-manager-api/orders",
    "method": "PUT",
    "backend": [
      {
        "url_pattern": "/orders",
        "host": ["http://store_manager:5000"],
      }
    ]
  },
```

Ensuite, **reconstruisez et red√©marrez** le conteneur Docker. 

### 4. Mettez √† jour la commande apr√®s le paiement
Si les √©tapes de l'activit√© 2 fonctionnent, cela signifie que les paiements sont trait√©s correctement. Cependant, si ces informations restent dans le service de paiement, elles ne sont pas tr√®s utiles. Modifiez `log430-labo05-payment` pour faire en sorte qu'il appelle l'endpoint `PUT /orders` dans `log430-labo05` pour mettre √† jour la commande de (modifier `is_paid` √† `true`). Utilisez les documents architecturaux disponibles dans `log430-labo05-payment` pour comprendre le fonctionnement du service et d√©terminer quel module ou quelle m√©thode doit √™tre modifi√©(e).

> ‚ö†Ô∏è ATTENTION : N'oubliez pas d'appeler l'endpoint tel que d√©crit dans `config/krakend.json`.

> üí° **Question 4** : Quelle m√©thode avez-vous d√ª modifier dans `log430-labo05-payment` et qu'avez-vous modifi√©e ? Justifiez avec un extrait de code.

### 5. Testez le rate limiting avec Locust
En plus de fonctionner en tant qu'une fa√ßade pour nos APIs, nous pouvons aussi utiliser KrakenD pour limiter l'acc√®s √† nos APIs et les prot√©ger des attaques DDOS, par exemple. Nous faisons √ßa avec rate limiting. Cr√©ez un nouveau test dans `locustfiles/locustfile.py` sp√©cifiquement pour tester le rate limiting :

```python
  @task(1)
  def test_rate_limit(self):
      """Test pour v√©rifier le rate limiting"""
      payload = {
          "user_id": random.randint(1, 3),
          "items": [{"product_id": random.randint(1, 4), "quantity": random.randint(1, 10)}] 
      }   
      
      response = self.client.post(
          "/store-manager-api/orders",
          json=payload
      )
      
      if response.status_code == 503:  # HTTP 503 Service Unavailable
          print("Rate limit atteint!")
```

Changez la ligne ci-dessous dans `docker-compose.yml` :

Avant:
```yml
command: -f /mnt/locust/locustfile.py --host=http://store_manager:5000

```

Apr√®s:
```yml
command: -f /mnt/locust/locustfile.py --host=http://api-gateway:8080
```

**Reconstruisez et red√©marrez** le conteneur Docker. Ensuite, dans votre navigateur, acc√©dez √† `http://localhost:8089` et configurez Locust avec :
- Number of users : 100 (total)
- Spawn rate : 1 (par seconde)
- Host : `http://api-gateway:8080` (l'adresse √† KrakenD)

Lancez le test et observez les r√©ponses HTTP 503 (Service Unavailable).

> üí° **Question 5** : √Ä partir de combien de requ√™tes par minute observez-vous les erreurs 503 ? Justifiez avec des captures d'√©cran de Locust.

### 6. Cr√©ez un endpoint de test pour le timeout
Dans `store_manager.py`, ajoutez un endpoint de test qui simule une r√©ponse lente :

```python
import time

@app.get('/test/slow/<int:delay_seconds>')
def test_slow_endpoint(delay_seconds):
    """Endpoint pour tester les timeouts"""
    time.sleep(delay_seconds)  # Simule une op√©ration lente
    return {"message": f"Response after {delay_seconds} seconds"}, 200
```

De plus, ajoutez cet endpoint √† `config/krakend.json`. Ensuite, **reconstruisez et red√©marrez** le conteneur Docker. 
```json
  {
    "endpoint": "/store-manager-api/test/slow/{delay}",
    "method": "GET",
    "backend": [
      {
        "url_pattern": "/test/slow/{delay}",
        "host": ["http://store_manager:5000"],
        "timeout": "5s"
      }
    ]
  }
```

Testez diff√©rents d√©lais en utilisant votre navigateur :
- `http://localhost:8080/store-manager-api/test/slow/2` 
- `http://localhost:8080/store-manager-api/test/slow/10` 

> üí° **Question 6** : Que se passe-t-il dans le navigateur quand vous faites une requ√™te avec un d√©lai sup√©rieur au timeout configur√© (5 secondes) ? Quelle est l'importance du timeout dans une architecture de microservices ? Justifiez votre r√©ponse avec des exemples pratiques.

### 7. √âx√©cutez un test de charge
Ex√©cutez un test de charge sur l'application Store Manager en utilisant Locust. 
- Si possible, d√©ployez Store Manager et le service de paiement dans deux VMs distinctes.
- Le cas √©ch√©ant, modifiez le `host` cible sur Locust pour qu'il corresponde √† l'adresse IP de la VM qui h√©berge l'application Store Manager.
- Suivez les m√™mes instructions que celles du laboratoire 4, activit√© 5. 
- Testez la cr√©ation d'une commande et notez vos observations sur les performances dans le rapport.

### 8. D√©ploiement avec Kubernetes (facultatif)
L'adoption d'une architecture en microsservices soul√®ve un d√©fi important : le d√©ploiement se complexifie, surtout lorsque chaque service est h√©berg√© sur un serveur distinct. Bien qu'il soit possible d'automatiser les tests et le d√©ploiement via GitHub CI, la configuration doit √™tre r√©p√©t√©e pour chaque nouvelle VM ou serveur, et il faut s'assurer que tous ex√©cutent la derni√®re version du code.

Pour simplifier et mieux mettre √† l'√©chelle ce processus, il est recommand√© d'utiliser un orchestrateur de conteneurs tel que [Kubernetes](https://github.com/kubernetes/kubernetes) (k8s). Consultez le tutoriel dans le fichier `ks3.md` pour en savoir plus. Bien que vos comp√©tences en Kubernetes ne soient pas √©valu√©es dans ce laboratoire, elles peuvent s'av√©rer pr√©cieuses lors du d√©ploiement de votre projet.

## üì¶ Livrables

- Un fichier .zip contenant l'int√©gralit√© du code source du projet Labo 05.
- Un rapport en .pdf r√©pondant aux questions pr√©sent√©es dans ce document. Il est obligatoire d'illustrer vos r√©ponses avec du code ou des captures d'√©cran/terminal.
